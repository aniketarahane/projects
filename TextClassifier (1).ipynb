{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f78350-d5a2-4a1e-b429-123e5948e7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aniketarahane/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/aniketarahane/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043e40d6-dc67-4718-8045-45bd497df976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LETTER OF RESPONSE 1/3/2015 Marcus Clinton 3 ...</td>\n",
       "      <td>roommate/family problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-- As a solution to the law soilt we ask to s...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: Ally Newman Fax: (253) 891-5440 To: Fax...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: Ally Newman Fax: (253) 891-5440 To: Fax...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: Ally Newman Fax: (253) 891-5440 To: Fax...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Eviction Summons Madrona Ridge Residential, L...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dec. 22. 2014. 3:40 PM ORD PLLC FUCKtilY ROX ...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>age : 2. of 2 01/7/2015 13:14 PM PHONE #30380...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kimani Kironji Emily Coates E, Jessie Lewis J...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>black mold, In attempt to have the landlord h...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01/08/2015 12:35 NO.141 #001 Mail Plus Copies...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Page: 002 R=95% ID:ATTORNEY From: 253 474 140...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From 2539851495 Fri 09 Jan 2015 03:30:06 PM E...</td>\n",
       "      <td>health problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jan, 8. 2015 11:19AM No. 6118 P. 2 Holum &amp; Ha...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01/05/2015 11:01 2535652913 UNIV PL LIB PAGE ...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>01/05/2015 11:01 2535652913 UNIV PL LIB PAGE ...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01/26/2015 19:03 2534721330 ACE 3102 PAGE 01 ...</td>\n",
       "      <td>health problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>01/26/2015 19:03 2534721330 ACE 3102 PAGE 02 ...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I found a house, but it would not be 1 ready ...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>01/16/2015 00:30 2034140008 GATEWAY 1645 Holu...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>01/16/2015 08:38 2534140880 SAFEWAY 1645 PAGE...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01/16/2015 08:38 2534140880 SAFEWAY 1645 PAGE...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>R=95% ID:ATTORNEY From: 2534608307 SEP-06-200...</td>\n",
       "      <td>health problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Page : 003 R=95% ID:ATTORNEY From: 2534608307...</td>\n",
       "      <td>health problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>From : Prairie Ridge 3608978378 01/20/2015 13...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>van. 17. 2015 |12:44PM `Vo. 2337 P. 2 - Jan. ...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PAGE 01/01 01/20/2015 13:06 2536205455 PIERCE...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Feb 03 15 04:47p michael murrray 3609156598 p...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Feb 03 15 04:47p michael murray 3609156598 p....</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Happer Property managent &amp; maintenance VS Leni...</td>\n",
       "      <td>roommate/family problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I am going to do my best by being a great ten...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>From : Medical Imaging NW 2535812844 01/23/20...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Guled Mohamed Abdullahi Defendant #41903.0241...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>01/23/2015 17:24 12535724329 .... RANKOS PAGE ...</td>\n",
       "      <td>roommate/family problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>01/23/2015 17:25 12535724329 RANKOS PAGE 01/0...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Joyce Blake 1718 South 84th Street, Apt# 47 T...</td>\n",
       "      <td>health problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1 ..... - 47 7. Notice to Pay or Vacate Deliv...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>- Certificate of Service- I Nicole Slettvet/ ...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>- Certificate of Service- I Nicole Slettvet/ ...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1/28/15 delivered before 5 PM EVICTION SUMMON...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>J'AIEU VOUV. 28,2015 DEBBIE KETRON DELIVERED ...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ALTHOUGH IT IS TRUE THAT JAN MICHELLAN PERSON...</td>\n",
       "      <td>landlord/rental agreement issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Holum &amp; Hann, P.S. JAN 2 8 2015 H We Jose Sot...</td>\n",
       "      <td>money/ job problems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0    LETTER OF RESPONSE 1/3/2015 Marcus Clinton 3 ...   \n",
       "1    -- As a solution to the law soilt we ask to s...   \n",
       "2    From: Ally Newman Fax: (253) 891-5440 To: Fax...   \n",
       "3    From: Ally Newman Fax: (253) 891-5440 To: Fax...   \n",
       "4    From: Ally Newman Fax: (253) 891-5440 To: Fax...   \n",
       "5    Eviction Summons Madrona Ridge Residential, L...   \n",
       "6    Dec. 22. 2014. 3:40 PM ORD PLLC FUCKtilY ROX ...   \n",
       "7    age : 2. of 2 01/7/2015 13:14 PM PHONE #30380...   \n",
       "8    Kimani Kironji Emily Coates E, Jessie Lewis J...   \n",
       "9    black mold, In attempt to have the landlord h...   \n",
       "10   01/08/2015 12:35 NO.141 #001 Mail Plus Copies...   \n",
       "11   Page: 002 R=95% ID:ATTORNEY From: 253 474 140...   \n",
       "12   From 2539851495 Fri 09 Jan 2015 03:30:06 PM E...   \n",
       "13   Jan, 8. 2015 11:19AM No. 6118 P. 2 Holum & Ha...   \n",
       "14   01/05/2015 11:01 2535652913 UNIV PL LIB PAGE ...   \n",
       "15   01/05/2015 11:01 2535652913 UNIV PL LIB PAGE ...   \n",
       "16   01/26/2015 19:03 2534721330 ACE 3102 PAGE 01 ...   \n",
       "17   01/26/2015 19:03 2534721330 ACE 3102 PAGE 02 ...   \n",
       "18   I found a house, but it would not be 1 ready ...   \n",
       "19   01/16/2015 00:30 2034140008 GATEWAY 1645 Holu...   \n",
       "20   01/16/2015 08:38 2534140880 SAFEWAY 1645 PAGE...   \n",
       "21   01/16/2015 08:38 2534140880 SAFEWAY 1645 PAGE...   \n",
       "22   R=95% ID:ATTORNEY From: 2534608307 SEP-06-200...   \n",
       "23   Page : 003 R=95% ID:ATTORNEY From: 2534608307...   \n",
       "24   From : Prairie Ridge 3608978378 01/20/2015 13...   \n",
       "25   van. 17. 2015 |12:44PM `Vo. 2337 P. 2 - Jan. ...   \n",
       "26   PAGE 01/01 01/20/2015 13:06 2536205455 PIERCE...   \n",
       "27   Feb 03 15 04:47p michael murrray 3609156598 p...   \n",
       "28   Feb 03 15 04:47p michael murray 3609156598 p....   \n",
       "29  Happer Property managent & maintenance VS Leni...   \n",
       "30   I am going to do my best by being a great ten...   \n",
       "31   From : Medical Imaging NW 2535812844 01/23/20...   \n",
       "32   Guled Mohamed Abdullahi Defendant #41903.0241...   \n",
       "33  01/23/2015 17:24 12535724329 .... RANKOS PAGE ...   \n",
       "34   01/23/2015 17:25 12535724329 RANKOS PAGE 01/0...   \n",
       "35   Joyce Blake 1718 South 84th Street, Apt# 47 T...   \n",
       "36   1 ..... - 47 7. Notice to Pay or Vacate Deliv...   \n",
       "37   - Certificate of Service- I Nicole Slettvet/ ...   \n",
       "38   - Certificate of Service- I Nicole Slettvet/ ...   \n",
       "39   1/28/15 delivered before 5 PM EVICTION SUMMON...   \n",
       "40   J'AIEU VOUV. 28,2015 DEBBIE KETRON DELIVERED ...   \n",
       "41   ALTHOUGH IT IS TRUE THAT JAN MICHELLAN PERSON...   \n",
       "42   Holum & Hann, P.S. JAN 2 8 2015 H We Jose Sot...   \n",
       "\n",
       "                          categories  \n",
       "0           roommate/family problems  \n",
       "1                money/ job problems  \n",
       "2   landlord/rental agreement issues  \n",
       "3   landlord/rental agreement issues  \n",
       "4   landlord/rental agreement issues  \n",
       "5   landlord/rental agreement issues  \n",
       "6                money/ job problems  \n",
       "7                money/ job problems  \n",
       "8   landlord/rental agreement issues  \n",
       "9   landlord/rental agreement issues  \n",
       "10               money/ job problems  \n",
       "11               money/ job problems  \n",
       "12                   health problems  \n",
       "13               money/ job problems  \n",
       "14               money/ job problems  \n",
       "15               money/ job problems  \n",
       "16                   health problems  \n",
       "17  landlord/rental agreement issues  \n",
       "18  landlord/rental agreement issues  \n",
       "19  landlord/rental agreement issues  \n",
       "20  landlord/rental agreement issues  \n",
       "21               money/ job problems  \n",
       "22                   health problems  \n",
       "23                   health problems  \n",
       "24               money/ job problems  \n",
       "25               money/ job problems  \n",
       "26               money/ job problems  \n",
       "27  landlord/rental agreement issues  \n",
       "28               money/ job problems  \n",
       "29          roommate/family problems  \n",
       "30               money/ job problems  \n",
       "31  landlord/rental agreement issues  \n",
       "32               money/ job problems  \n",
       "33          roommate/family problems  \n",
       "34               money/ job problems  \n",
       "35                   health problems  \n",
       "36  landlord/rental agreement issues  \n",
       "37               money/ job problems  \n",
       "38               money/ job problems  \n",
       "39  landlord/rental agreement issues  \n",
       "40  landlord/rental agreement issues  \n",
       "41  landlord/rental agreement issues  \n",
       "42               money/ job problems  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('~/Downloads/dataset - Sheet2 (1).csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1701afcf-8824-4117-85fe-6acc3642d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aniketarahane/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     letter response marcus clinton correct graham ...\n",
       "1     solution law soil ask set payment roman comedi...\n",
       "2     ally german fax fax page law office keen knuts...\n",
       "3     ally german fax fax page found property th ave...\n",
       "4     ally german fax fax page know going people loo...\n",
       "5     election summons matrena ridge residential pla...\n",
       "6     dec pm ord luckily box p dec may concern respo...\n",
       "7     age pm phone bent wright caesar ra tillman dat...\n",
       "8     kimani kironji emily coat e sessile lewis jan ...\n",
       "9     black mold attempt landlord handle matter agre...\n",
       "10    mail plus copy olympic dr te h gig harbor wa g...\n",
       "11    page r id attorney aug mark hue vasili plainti...\n",
       "12    fro jan pm est page laurel blunt hannah pierce...\n",
       "13    jan p hour hand p dec hour hand p h st sarcoma...\n",
       "14    unit limb page pocket ty bedford january th b ...\n",
       "15    unit limb page und sent fee court cast whateve...\n",
       "16    ace page please fax rickets response confine d...\n",
       "17    ace page following attempt deliver notice date...\n",
       "18    found house would ready week manager owner ins...\n",
       "19    gateway hound hand att everett hour fax si cau...\n",
       "20    safety page spot tenant staff rise cocci west ...\n",
       "21    safety page resolved without legal world appro...\n",
       "22    r id attorney see january name constrillana an...\n",
       "23    page r id attorney see doctor doctor note supp...\n",
       "24    prairie ridge p clerk office january ryder aff...\n",
       "25    van pm vo p jan donald e allen attorney law st...\n",
       "26    page pierce co sg auto donald e allen attorney...\n",
       "27    feb p michael murray p dare james st helene av...\n",
       "28    feb p michael murray p date send pocket bedfor...\n",
       "29    happen property managed maintenance v lenisha ...\n",
       "30    going best great tenant paying en time angle p...\n",
       "31    medical imagine p hour hand p jan may concern ...\n",
       "32    ruled ashamed abdullahi defendant january writ...\n",
       "33    rank page fax pocket bedford january may conce...\n",
       "34    rank page st overwhelmed remainder le amount i...\n",
       "35    blame south th street apt sarcoma wa phone ema...\n",
       "36    notice pay vacated delivered january st defend...\n",
       "37    certificate service nice slettvet zimmerman ma...\n",
       "38    certificate service nice slettvet zimmerman ma...\n",
       "39    delivered pm election summons seven michael re...\n",
       "40    j dieu vous debate retro delivered fera hill a...\n",
       "41    although true jan mcclellan personally handed ...\n",
       "42    hour hand p jan h jose soto mitchell respondin...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_tags(string):\n",
    "    result = re.findall(\"[a-zA-Z]+\",string)\n",
    "    result = (\" \".join(result))\n",
    "    result = result.lower()\n",
    "    new_doc = TextBlob(result)\n",
    "    #result = (\"\".join(result))\n",
    "    result = new_doc.correct()\n",
    "    result = (\"\".join(result))\n",
    "    #result = re.sub('','',string)          #remove HTML tags; not really necessary\n",
    "    #result = re.sub('https://.*','',result)   #remove URLs; not really necessary\n",
    "    #result = re.sub(r'[^w'+removelist+']', ' ',result)    #remove non-alphanumeric characters; for some reason this makes everything a w which is annoying because this is really the only necessary one for this dataset\n",
    "    return result\n",
    "dataset['text'] = dataset['text'].apply(lambda cw : remove_tags(cw))\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) #gets rid of meaningless words\n",
    "dataset['text'] = dataset['text'].apply(lambda x: ' '. join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "dataset\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    st = \"\"\n",
    "    for w in w_tokenizer.tokenize(text):\n",
    "           st = st + lemmatizer.lemmatize(w) + \" \"\n",
    "    return st\n",
    "dataset['text'] = dataset.text.apply(lemmatize_text)\n",
    "dataset['text'] \n",
    "#I wanted to do a spelling correcting since a lot of the words were spelt wrong but it was taking way too long to run; i will try to find a more efficient method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb79351-a427-4f4e-a1f3-5acb8c22e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = dataset['text'].values\n",
    "labels = dataset['categories'].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)#pretty self explanatory just encodes values to the labels and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e163f6a4-1bca-434d-9b0c-e51d02f35f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b811b94a-ba6b-4ab7-a97c-d172264a1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(max_features = 3000)\n",
    "X = vec.fit_transform(train_sentences)\n",
    "vocab = vec.get_feature_names_out()\n",
    "X = X.toarray()\n",
    "word_counts = {}\n",
    "for l in range(4):\n",
    "    word_counts[l] = defaultdict(lambda: 0)\n",
    "for i in range(X.shape[0]):\n",
    "    l = train_labels[i]\n",
    "    for j in range(len(vocab)):\n",
    "        word_counts[l][vocab[j]] += X[i][j]\n",
    "#so now we're starting to build a naive bayes classifier; couldve used a variant from sklearn library but just to get a better understanding of how it works we'll break up the parts;\n",
    "#vectorized(words to real numbers) and put in dictionary  which is word_counts and vocab is unique words\n",
    "#also so there is obviously gonna be words in test set that are not in training set so to make sure that that one word probability isn't 0 we are gonn do laplace smoothing which is really just adding 1\n",
    "def laplace_smoothing(n_label_items, vocab, word_counts, word, text_label):\n",
    "    a = word_counts[text_label][word] + 1\n",
    "    b = n_label_items[text_label] + len(vocab)\n",
    "    return math.log(a/b)\n",
    "def group_by_label(x, y, labels):\n",
    "    data = {}\n",
    "    for l in labels:\n",
    "        data[l] = x[np.where(y == l)]\n",
    "    return data\n",
    "def fit(x, y, labels):\n",
    "    n_label_items = {}\n",
    "    log_label_priors = {}\n",
    "    n = len(x)\n",
    "    grouped_data = group_by_label(x, y, labels)\n",
    "    for l, data in grouped_data.items():\n",
    "        n_label_items[l] = len(data)\n",
    "        log_label_priors[l] = math.log(n_label_items[l] / n)\n",
    "    return n_label_items, log_label_priors\n",
    "def predict(n_label_items, vocab, word_counts, log_label_priors, labels, x):\n",
    "    result = []\n",
    "    for text in x:\n",
    "        label_scores = {l: log_label_priors[l] for l in labels}\n",
    "        words = set(w_tokenizer.tokenize(text))\n",
    "        for word in words:\n",
    "            if word not in vocab: continue\n",
    "            for l in labels:\n",
    "                log_w_given_l = laplace_smoothing(n_label_items, vocab, word_counts, word, l)\n",
    "                label_scores[l] += log_w_given_l\n",
    "        result.append(max(label_scores, key=label_scores.get))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314b17a0-12ae-441b-ae34-9f2466d547a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediction on test set :  0.7272727272727273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [0,1,2,3]\n",
    "n_label_items, log_label_priors = fit(train_sentences,train_labels,labels)\n",
    "pred = predict(n_label_items, vocab, word_counts, log_label_priors, labels, test_sentences)\n",
    "\n",
    "print(\"Accuracy of prediction on test set : \", accuracy_score(test_labels,pred))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb877f-75a1-42b1-8fd1-d4897b824e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
